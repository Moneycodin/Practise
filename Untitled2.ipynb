{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235be00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Explain the core components of the Hadoop ecosystem and their respective roles in processing and\n",
    "storing big data. Provide a brief overview of HDFS, MapReduce, and YARN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b439322",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. Discuss the Hadoop Distributed File System (HDFS) in detail. Explain how it stores and manages data in a\n",
    "distributed environment. Describe the key concepts of HDFS, such as NameNode, DataNode, and blocks, and\n",
    "how they contribute to data reliability and fault tolerance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7f3c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. Write a step-by-step explanation of how the MapReduce framework works. Use a real-world example to\n",
    "illustrate the Map and Reduce phases. Discuss the advantages and limitations of MapReduce for processing\n",
    "large datasets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e0e4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "4. Explore the role of YARN in Hadoop. Explain how it manages cluster resources and schedules applications.\n",
    "Compare YARN with the earlier Hadoop 1.x architecture and highlight the benefits of YARN.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa98090",
   "metadata": {},
   "outputs": [],
   "source": [
    "5. Provide an overview of some popular components within the Hadoop ecosystem, such as HBase, Hive, Pig,\n",
    "and Spark. Describe the use cases and differences between these components. Choose one component and\n",
    "explain how it can be integrated into a Hadoop ecosystem for specific data processing tasks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67920ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "6. Explain the key differences between Apache Spark and Hadoop MapReduce. How does Spark overcome\n",
    "some of the limitations of MapReduce for big data processing tasks?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c4dcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "7. Write a Spark application in Scala or Python that reads a text file, counts the occurrences of each word,\n",
    "and returns the top 10 most frequent words. Explain the key components and steps involved in this\n",
    "application.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f770ae36",
   "metadata": {},
   "outputs": [],
   "source": [
    "8. Using Spark RDDs (Resilient Distributed Datasets), perform the following tasks on a dataset of your\n",
    "choice:\n",
    "a. Filter the data to select only rows that meet specific criteria.\n",
    "b. Map a transformation to modify a specific column in the dataset.\n",
    "c. Reduce the dataset to calculate a meaningful aggregation (e.g., sum, average).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce005d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "9. Create a Spark DataFrame in Python or Scala by loading a dataset (e.g., CSV or JSON) and perform the\n",
    "following operations:\n",
    "a. Select specific columns from the DataFrame.\n",
    "b. Filter rows based on certain conditions.\n",
    "c. Group the data by a particular column and calculate aggregations (e.g., sum, average).\n",
    "d. Join two DataFrames based on a common key.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbaeeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "10. Set up a Spark Streaming application to process real-time data from a source (e.g., Apache Kafka or a\n",
    "simulated data source). The application should:\n",
    "a. Ingest data in micro-batches.\n",
    "b. Apply a transformation to the streaming data (e.g., filtering, aggregation).\n",
    "c. Output the processed data to a sink (e.g., write to a file, a database, or display it).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d69c7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "11. Explain the fundamental concepts of Apache Kafka. What is it, and what problems does it aim to solve in\n",
    "the context of big data and real-time data processing?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3e916d",
   "metadata": {},
   "outputs": [],
   "source": [
    "12. Describe the architecture of Kafka, including its key components such as Producers, Topics, Brokers,\n",
    "Consumers, and ZooKeeper. How do these components work together in a Kafka cluster to achieve data\n",
    "streaming?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe53220d",
   "metadata": {},
   "outputs": [],
   "source": [
    "13. Create a step-by-step guide on how to produce data to a Kafka topic using a programming language of\n",
    "your choice and then consume that data from the topic. Explain the role of Kafka producers and consumers\n",
    "in this process.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aae5d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "14. Discuss the importance of data retention and data partitioning in Kafka. How can these features be\n",
    "configured, and what are the implications for data storage and processing?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bc6aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "15. Give examples of real-world use cases where Apache Kafka is employed. Discuss why Kafka is the\n",
    "preferred choice in those scenarios, and what benefits it brings to the table."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
